{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_eFvJha_oUbn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj-RjIPWoUbq",
        "outputId": "ae4268e6-1b0e-46c0-9037-0ff213dc3e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda for this proj!\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device} for this proj!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjlBfD2bCLi5"
      },
      "source": [
        "### RNN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yFfIWCUyoUbr"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, device):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.device = device\n",
        "\n",
        "        self.rnn_layer = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.dense_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, unbatched = False):\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        if unbatched:\n",
        "            h0 = torch.zeros(self.num_layers, self.hidden_size).requires_grad_()\n",
        "        else:\n",
        "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).requires_grad_()\n",
        "\n",
        "        h0 = h0.to(self.device)\n",
        "\n",
        "        if unbatched:\n",
        "          return self.dense_layer(self.rnn_layer(x, h0)[0][-1,:])\n",
        "        else:\n",
        "          return self.dense_layer(self.rnn_layer(x, h0)[0][:,-1,:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlmC7K8HCLi8"
      },
      "source": [
        "### LSTM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6utA3c5UCLi8"
      },
      "outputs": [],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, device):\n",
        "        super(LSTM, self).__init__() #Calls the constructor of the superclass nn.Module\n",
        "        self.device = device\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "\n",
        "    def forward(self, input: torch.tensor, unbatched: bool = False):\n",
        "        batch_size = input.shape[0]\n",
        "        if unbatched:\n",
        "            h0 = torch.zeros(self.num_layers, self.hidden_dim).requires_grad_()\n",
        "            c0 = torch.zeros(self.num_layers, self.hidden_dim).requires_grad_()\n",
        "        else:\n",
        "            h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).requires_grad_()\n",
        "            c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).requires_grad_()\n",
        "\n",
        "        h0 = h0.to(self.device)\n",
        "        c0 = c0.to(self.device)\n",
        "\n",
        "        out, (hn, c_n) = self.lstm(input, (h0, c0))\n",
        "        if unbatched:\n",
        "            out = self.fc(out[-1, :])  # out[-1] will give the hidden state at the last time step\n",
        "        else:\n",
        "            out = self.fc(out[:, -1, :])  # out[:, -1, :] will give the hidden state at the last time step for each sequence\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7d8NDXYCLi9"
      },
      "source": [
        "### GRU:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lBRw6D7cCLi-"
      },
      "outputs": [],
      "source": [
        "class GRU(nn.Module):\n",
        "    def __init__(self, n_features, hidden_size, n_layers, output_size, device):\n",
        "        super(GRU, self).__init__()\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.n_features = n_features\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.gru = nn.GRU(n_features,\n",
        "                          hidden_size=hidden_size,\n",
        "                          num_layers=n_layers,\n",
        "                          batch_first=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_features * hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, unbatched = False):\n",
        "        batch_size = x.size(0)\n",
        "        if unbatched:\n",
        "            h0 = torch.zeros(self.n_layers, self.hidden_size).to(self.device)\n",
        "        else:\n",
        "            h0 = torch.zeros(self.n_layers, batch_size, self.hidden_size).to(self.device)\n",
        "\n",
        "        out, _ = self.gru(x, h0)\n",
        "        if unbatched:\n",
        "            return self.fc1(out[-1,:])\n",
        "        else:\n",
        "            return self.fc1(out[:,-1,:])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WETlTXCLi-"
      },
      "source": [
        "### Transformer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lHJ6DqciCLi_"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.encoding = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
        "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.encoding = self.encoding.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        encoding = self.encoding.to(device)\n",
        "        return x + encoding[:, :x.size(1)]\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, num_features, d_model, nhead, num_layers, output_size, max_len=5000):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
        "        self.encoder = nn.Linear(num_features, d_model)\n",
        "        self.transformer = nn.Transformer(d_model, nhead, num_layers, num_layers, batch_first=True)\n",
        "        self.decoder = nn.Linear(d_model, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)  # Project input to model dimension\n",
        "        x = self.positional_encoding(x) # Add positional encoding\n",
        "        x = self.transformer(x, x)\n",
        "        x = self.decoder(x[:, -1, :])\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN1D_ForeCastModel(nn.Module):\n",
        "    def __init__(self, n_features, sequence_length, output_size):\n",
        "        super(CNN1D_ForeCastModel, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=n_features, out_channels=16, kernel_size=3, padding=1) \n",
        "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(32 * (sequence_length // 4), 50) \n",
        "        self.fc2 = nn.Linear(50, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0,2,1) #CNN expects (batch_size, n_features, sequence_length)\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1KxmnJiCoUbs"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesDatasetSin(Dataset):\n",
        "    def __init__(self,x):\n",
        "        self.x = x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self,i):\n",
        "        return self.x[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCQKfvGuoUbt"
      },
      "source": [
        "### Functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lq1QlUCcoUbu"
      },
      "outputs": [],
      "source": [
        "def sin(x, frequency = 0, shift = 0, noise = 0):\n",
        "        return np.sin(frequency*x+shift) + np.random.rand(len(x)) * noise\n",
        "\n",
        "def sin_sin(x, frequency = 0, shift = 0, noise = 0):\n",
        "        return (np.sin(frequency/4 * x+shift)  + np.sin(frequency*x)) #+ np.random.rand(len(x)) * noise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlRMCbLjCLjC"
      },
      "source": [
        "### Data preparation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4mCsTPRDoUbv"
      },
      "outputs": [],
      "source": [
        "def get_sequence(y, sequence_length):\n",
        "    sequences = []\n",
        "    for index in range(len(y) - sequence_length):\n",
        "        sequence = y[index : index + sequence_length]\n",
        "        sequences.append(sequence)\n",
        "    return torch.tensor(sequences, dtype = torch.float32)\n",
        "\n",
        "\n",
        "def make_multistep_dataset(func, num_funcs, sequence_length, sin_sin = False):\n",
        "    xfl = np.arange(0,100,0.01)\n",
        "    xtr = xfl[:int(0.8*len(xfl))]\n",
        "    xts = xfl[int(0.8*len(xfl)):]\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "    train = []\n",
        "    test = []\n",
        "\n",
        "    test_viz = [] #for visualisation of test performance\n",
        "    for i in range(num_funcs):\n",
        "        shift = 2 * torch.pi * torch.rand(1).item()\n",
        "        if sin_sin == True:\n",
        "          frequency =  15 + (30 * torch.rand(1).item())\n",
        "        else:\n",
        "          frequency = 20 * torch.rand(1).item()\n",
        "\n",
        "        noise = 0.1 * torch.rand(1).item()\n",
        "\n",
        "        train_data, test_data = scaler.fit_transform(func(xtr, frequency = frequency, shift = shift, noise = noise).reshape(-1,1)), scaler.fit_transform(func(xts, frequency = frequency, shift = shift, noise = noise).reshape(-1,1))\n",
        "        train_data, test_data = np.squeeze(train_data), np.squeeze(test_data)\n",
        "\n",
        "        train_sequence = get_sequence(train_data, sequence_length)\n",
        "        test_sequence = get_sequence(test_data, sequence_length)\n",
        "\n",
        "        train.append(train_sequence)\n",
        "        test.append(test_sequence)\n",
        "\n",
        "        test_viz.append(test_data)\n",
        "\n",
        "    train, test = torch.cat(train, dim=0).unsqueeze(2), torch.cat(test, dim=0).unsqueeze(2)\n",
        "\n",
        "    train_dataset = TimeSeriesDatasetSin(train)\n",
        "    test_dataset = TimeSeriesDatasetSin(test)\n",
        "\n",
        "    #train loaders\n",
        "    batch_size = 16\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader, torch.tensor(test_viz, dtype = torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMpDQe-lCLjE"
      },
      "source": [
        "### Training and testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5jLna5GzoUbw"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, dataloader, num_epochs, loss_func, prediction_horizon: int, rnn: bool):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        total_batches = len(dataloader)\n",
        "        for i, batch in enumerate(\n",
        "            tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", ncols=100)\n",
        "        ):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x = batch[:, :-prediction_horizon].to(\n",
        "                device\n",
        "            )  # All but the last n elements of each sequence\n",
        "            targets = batch[:, -prediction_horizon:].to(\n",
        "                device\n",
        "            )  # Last n elements is targets\n",
        "            targets = targets.squeeze()  # [batch_size, 1, 1] -> [batch_size]\n",
        "\n",
        "            outputs = model(x)  # Forward pass\n",
        "            outputs = outputs.squeeze()  # [batch_size, 1] -> [batch_size]\n",
        "\n",
        "            loss = loss_func(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            if rnn == True:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 5) #max_grad_norm = 5.\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        '''\n",
        "        # Print gradient values\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.grad is not None:\n",
        "                print(f\"Parameter: {name}, Gradient norm: {param.grad.norm().item()}\")\n",
        "        '''\n",
        "        avg_loss = running_loss / total_batches\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.10f}\")\n",
        "\n",
        "\n",
        "def test(net, forecast_steps, test_loader):\n",
        "    device = next(net.parameters()).device\n",
        "    loss_function = nn.MSELoss(reduction = 'mean')\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        tot_test_loss = 0.0\n",
        "        n_batches = len(test_loader)\n",
        "        for batch in test_loader:\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            test_pred = net(batch[:,:-forecast_steps])\n",
        "\n",
        "            test_loss = loss_function(test_pred, batch[:,-forecast_steps:].squeeze(2))\n",
        "\n",
        "            tot_test_loss += test_loss.item()\n",
        "        return tot_test_loss/n_batches\n",
        "\n",
        "'''\n",
        "def test_2(net, forecast_steps, test_seq):\n",
        "    device = next(net.parameters()).device\n",
        "    loss_function = nn.MSELoss(reduction = 'mean')\n",
        "    net.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        tot_test_loss = 0.0\n",
        "        n_seq = len(test_seq)\n",
        "        for i in range(len(test_seq)):\n",
        "            input_length = len(test_seq[i])-forecast_steps\n",
        "            input = test_seq[i][0:input_length]\n",
        "            target = test_seq[i][input_length:input_length + forecast_steps]\n",
        "\n",
        "            input_tensor = torch.tensor(input).to(device)\n",
        "            input_tensor = input_tensor.unsqueeze(0)\n",
        "            test_pred = net(input_tensor).cpu()\n",
        "\n",
        "            test_loss = loss_function(test_pred.squeeze(0), target.squeeze(1))\n",
        "\n",
        "            tot_test_loss += test_loss.item()\n",
        "\n",
        "        return tot_test_loss/n_seq\n",
        "'''\n",
        "\n",
        "def forecast(net, ts_viz, sequence_length, forecast_steps, model_type: str, plot=True):\n",
        "    device = next(net.parameters()).device\n",
        "    historical_data = ts_viz[:, :sequence_length-forecast_steps].unsqueeze(2)\n",
        "    hist_data_plot = historical_data.squeeze(2).detach().numpy()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        historical_data = historical_data.to(device)\n",
        "        pred = net(historical_data)\n",
        "\n",
        "    if plot:\n",
        "        days = np.arange(1, sequence_length + 1)\n",
        "        num_plots = len(ts_viz)\n",
        "        n_rows, n_cols = 2, 3  # Define the grid dimensions\n",
        "        fig, axs = plt.subplots(n_rows, n_cols, figsize=(20, 10))\n",
        "        axs = axs.flatten()  # Flatten the 2D array of axes to 1D for easy iteration\n",
        "\n",
        "        for i in range(num_plots):\n",
        "            vals = ts_viz[i, sequence_length-forecast_steps:sequence_length].cpu().numpy()\n",
        "            pred_cpu = pred[i].cpu().numpy()  # Move prediction to CPU\n",
        "            ax = axs[i]\n",
        "            ax.plot(days[:-forecast_steps], hist_data_plot[i], 'o-', label='Test data')\n",
        "            ax.plot(days[-forecast_steps:], pred_cpu, 'o-', label='Forecasted values')\n",
        "            ax.plot(days[-forecast_steps:], vals, '.-', alpha=0.3, label='Actual values', color='tab:blue')\n",
        "            ax.set_title(f'Forecast of {len(pred[0])} days for {model_type}')\n",
        "            ax.set_xlabel('Days')\n",
        "            ax.grid(True)\n",
        "            if i == 0:\n",
        "                ax.legend()  # Add legend to the first plot only to avoid clutter\n",
        "\n",
        "        # Hide any unused subplots\n",
        "        for j in range(i + 1, n_rows * n_cols):\n",
        "            fig.delaxes(axs[j])\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{model_type}')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFzTjDM1CLjF"
      },
      "source": [
        "### Normal sine-functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhLI4DxnCLjG",
        "outputId": "bc1af97d-1f9b-4044-ab44-83a17384a3f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-f740e48542c3>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
            "  return torch.tensor(sequences, dtype = torch.float32)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Transformer: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:46<00:00, 63.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Average Loss: 0.0422658611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:40<00:00, 71.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Average Loss: 0.0099604105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:41<00:00, 71.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Average Loss: 0.0056710658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:41<00:00, 70.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Average Loss: 0.0037601940\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:42<00:00, 69.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Average Loss: 0.0028423267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:40<00:00, 72.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Average Loss: 0.0023509050\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:40<00:00, 72.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Average Loss: 0.0020666781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:40<00:00, 72.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Average Loss: 0.0018259006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:41<00:00, 71.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Average Loss: 0.0016645189\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:40<00:00, 72.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Average Loss: 0.0015148731\n",
            "----------------------------------------------\n",
            "Training RNN: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:14<00:00, 197.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Average Loss: 0.2424208873\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:14<00:00, 198.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Average Loss: 0.2962045582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:15<00:00, 193.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Average Loss: 0.3199226066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:16<00:00, 182.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Average Loss: 0.3199798008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:15<00:00, 192.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Average Loss: 0.0535474163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:15<00:00, 195.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Average Loss: 0.0330449289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:15<00:00, 192.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Average Loss: 0.0283149701\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:15<00:00, 191.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Average Loss: 0.0816186474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:15<00:00, 195.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Average Loss: 0.0062036206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|█████████████████████████████████████████████| 2944/2944 [00:15<00:00, 194.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Average Loss: 0.0049270394\n",
            "----------------------------------------------\n",
            "Training GRU: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 125.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Average Loss: 0.2302809828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 125.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Average Loss: 0.0197799597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 125.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Average Loss: 0.0091370452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 126.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Average Loss: 0.0068628496\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 125.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Average Loss: 0.0056685900\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 126.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Average Loss: 0.0048386109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 124.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Average Loss: 0.0043322762\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 124.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Average Loss: 0.0039624567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████████████████████████████████████████| 2944/2944 [00:23<00:00, 125.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Average Loss: 0.0034800828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|█████████████████████████████████████████████| 2944/2944 [00:23<00:00, 125.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Average Loss: 0.0030488613\n",
            "----------------------------------------------\n",
            "Training LSTM: \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:30<00:00, 96.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Average Loss: 0.2608388284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:30<00:00, 96.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Average Loss: 0.0250277708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:30<00:00, 95.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Average Loss: 0.0095973718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|███████████████████████████████████████████████| 2944/2944 [00:30<00:00, 96.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Average Loss: 0.0065313283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10:  69%|████████████████████████████████▍              | 2030/2944 [00:21<00:09, 97.52it/s]"
          ]
        }
      ],
      "source": [
        "#hyperparameters for transformer\n",
        "num_features = 1\n",
        "d_model = 64\n",
        "nhead = 4\n",
        "num_layers_transformer = 2\n",
        "\n",
        "#hyperparameters for rnns\n",
        "forecast_steps = 50\n",
        "sequence_length = 100 + forecast_steps\n",
        "num_funcs = 6\n",
        "\n",
        "input_size = 1\n",
        "hidden_size = 512\n",
        "output_size = forecast_steps\n",
        "num_layers = 1\n",
        "\n",
        "transformer_model = TransformerModel(num_features, d_model, nhead, num_layers_transformer, output_size).to(device)\n",
        "rnn_model = RNN(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
        "lstm_model = LSTM(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
        "gru_model = GRU(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
        "cnn_model = CNN1D_ForeCastModel(num_features, sequence_length, output_size).to(device)\n",
        "\n",
        "models = {'Transformer': transformer_model, 'RNN': rnn_model, 'GRU': gru_model, 'LSTM': lstm_model, 'CNN': cnn_model}\n",
        "optimizers = {\n",
        "    'Transformer': optim.SGD(transformer_model.parameters(), lr=0.1),\n",
        "    'RNN' : optim.SGD(rnn_model.parameters(), lr=0.1),\n",
        "    'LSTM': optim.SGD(lstm_model.parameters(), lr=0.1),\n",
        "    'GRU': optim.SGD(gru_model.parameters(), lr=0.1),\n",
        "    'CNN': optim.SGD(cnn_model.parameters(), lr=0.1)\n",
        "}\n",
        "\n",
        "loss_function = nn.MSELoss(reduction = 'mean')\n",
        "\n",
        "trloader_sin, tsloader_sin, ts_viz = make_multistep_dataset(sin, num_funcs, sequence_length)\n",
        "\n",
        "#train all models\n",
        "for model in models.keys():\n",
        "    rnn = False\n",
        "    print(f'Training {model}: ')\n",
        "    if model == 'RNN':\n",
        "        rnn = True\n",
        "    train(models[model], optimizers[model], trloader_sin, num_epochs=10, loss_func=loss_function, prediction_horizon=forecast_steps, rnn = rnn)\n",
        "    print('----------------------------------------------')\n",
        "#plot of forecast\n",
        "\n",
        "for model in models.keys():\n",
        "    forecast(models[model], ts_viz, sequence_length, forecast_steps, f'{model}')\n",
        "\n",
        "#train(rnn_sin, optimizer, trloader_sin, num_epochs=10, loss_func=loss_function, prediction_horizon=forecast_steps, max_grad_norm=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ0J5CphoUb0"
      },
      "source": [
        "### More advanced sin-functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjERUin4oUb1"
      },
      "outputs": [],
      "source": [
        "#hyperparameters for transformer\n",
        "num_features = 1\n",
        "d_model = 64\n",
        "nhead = 4\n",
        "num_layers_transformer = 3\n",
        "\n",
        "#hyperparameters for rnns\n",
        "forecast_steps = 50\n",
        "sequence_length = 200 + forecast_steps\n",
        "num_funcs = 6\n",
        "\n",
        "input_size = 1\n",
        "hidden_size = 512\n",
        "output_size = forecast_steps\n",
        "num_layers = 1\n",
        "\n",
        "transformer_model_adv = TransformerModel(num_features, d_model, nhead, num_layers_transformer, output_size).to(device)\n",
        "rnn_model_adv = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "lstm_model_adv = LSTM(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
        "gru_model_adv = GRU(input_size, hidden_size, num_layers, output_size, device).to(device)\n",
        "cnn_model = CNN1D_ForeCastModel(num_features, sequence_length, output_size).to(device)\n",
        "\n",
        "models_adv = {'Transformer': transformer_model_adv, 'RNN': rnn_model_adv, 'GRU': gru_model_adv, 'LSTM': lstm_model_adv}\n",
        "optimizers_adv = {\n",
        "    'Transformer': optim.SGD(transformer_model_adv.parameters(), lr=0.1),\n",
        "    'RNN' : optim.SGD(rnn_model_adv.parameters(), lr=0.1),\n",
        "    'LSTM': optim.SGD(lstm_model_adv.parameters(), lr=0.1),\n",
        "    'GRU': optim.SGD(gru_model_adv.parameters(), lr=0.1),\n",
        "}\n",
        "\n",
        "trloader_adv, tsloader_adv, ts_viz_adv = make_multistep_dataset(sin_sin, num_funcs, sequence_length, sin_sin = True)\n",
        "\n",
        "#train all models\n",
        "for model in models_adv.keys():\n",
        "    rnn = False\n",
        "    print(f'Training {model}: ')\n",
        "    if model == 'RNN':\n",
        "        rnn = True\n",
        "    train(models_adv[model], optimizers_adv[model], trloader_adv, num_epochs=10, loss_func=loss_function, prediction_horizon=forecast_steps, rnn = rnn)\n",
        "    print('----------------------------------------------')\n",
        "\n",
        "#plot of forecast\n",
        "for model in models_adv.keys():\n",
        "    forecast(models_adv[model], ts_viz_adv, sequence_length, forecast_steps, f'{model}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
